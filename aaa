# excel_reader.py
import pandas as pd
from datetime import datetime, timedelta
import logging

logging.basicConfig(level=logging.INFO)

class StubbingFileHandler:
    def __init__(self, stubbing_file_path):
        self.stubbing_file_path = stubbing_file_path
        self.stubbing_file = pd.ExcelFile(stubbing_file_path)
        logging.info(f"Loaded Excel file: {stubbing_file_path}")

    def read_sheet(self, sheet_name, dtype=str):
        logging.info(f"Reading sheet: {sheet_name}")
        return pd.read_excel(self.stubbing_file, sheet_name, dtype=dtype).fillna('')

    def add_stubbing_result_sheet(self, trade_df, sheet_name):
        trade_df = trade_df.fillna('')
        trade_df = trade_df.sort_values(by=['TradeID', 'IsTradeID'], ascending=[False, False])

        with pd.ExcelWriter(self.stubbing_file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
            trade_df.to_excel(writer, sheet_name=sheet_name, index=False)

        logging.info(f"DataFrame has been written to the Excel file '{self.stubbing_file_path}'.")

import pandas as pd


# excel_processor.py
# from excel_reader import ExcelReader
# from data_processor import DataProcessor

class TradeDataProcessor:
    def __init__(self, stubbing_file_path):
        self.stubbing_file_handler = StubbingFileHandler(stubbing_file_path)
        self.trade_details_df = self.stubbing_file_handler.read_sheet("TradeDetails")
        self.common_fields_df = self.stubbing_file_handler.read_sheet("CommonFields")
        self.rules_df = self.stubbing_file_handler.read_sheet("Rules")
        logging.info("Initialized TradeDataProcessor")

    def get_trade_details_dfs(self):
        return self.trade_details_df

    def get_common_fields_dfs(self):
        return self.common_fields_df

    def get_rules_dfs(self):
        return self.rules_df


    def filter_unique_trade_rows(self):
        filter_criteria_cols = [col for col in self.trade_details_df.columns if
                                col not in ['TradeID', 'Path', 'Value', 'RuleID']]
        unique_rows_df = self.trade_details_df[['TradeID'] + filter_criteria_cols]
        unique_rows_df = unique_rows_df.drop_duplicates()
        logging.info("Filtered unique trade rows")
        return unique_rows_df


    def generate_new_trade_identifier_df(self, unique_trade_rows_df):
        processed_trades_df = pd.DataFrame(columns=unique_trade_rows_df.columns.tolist() + self.common_fields_df.columns.tolist())

        for _, row in unique_trade_rows_df.iterrows():
            for _, common_row in self.common_fields_df.iterrows():
                combined_row = pd.concat([row, common_row])
                processed_trades_df = processed_trades_df._append(combined_row, ignore_index=True)
        logging.info("Generated new trade identifier DataFrame")
        return processed_trades_df

    def generate_stub_trades_with_identifiers_df(self):
        unique_trade_rows_df = self.filter_unique_trade_rows()
        new_trade_identifier_df = self.generate_new_trade_identifier_df(unique_trade_rows_df)
        stubbed_trades_with_identifiers_df = pd.concat([self.trade_details_df, new_trade_identifier_df], ignore_index=True)
        logging.info("Generated stubbed trades with identifiers DataFrame")
        return stubbed_trades_with_identifiers_df

    def create_trade_id_rule_mappings(self, trade_df):
        trade_id_rules_dict = {}
        for index, row in trade_df.iterrows():
            trade_id = row['TradeID']
            rule_id = row['RuleID']

            if trade_id not in trade_id_rules_dict:
                trade_id_rules_dict[trade_id] = {}
            if rule_id:
                trade_id_rules_dict[trade_id][rule_id] = None
        logging.info("Created trade ID rule mappings")
        return trade_id_rules_dict

    def update_trade_df_with_rules_dict(self, trade_df, rules_dict):
        for index, row in trade_df.iterrows():
            trade_id = row['TradeID']
            rule_id = row['RuleID']
            if pd.notna(rule_id) and rule_id != '':
                if trade_id in rules_dict and rule_id in rules_dict[trade_id]:
                    new_value = rules_dict[trade_id][rule_id]
                    trade_df.at[index, 'Value'] = new_value
                else:
                    raise ValueError(f"Rule ID {rule_id} not present for Trade ID {trade_id}")
        logging.info("Updated trade DataFrame with rules dictionary")
        return trade_df

    def map_generated_id_with_trades(self, df):
        trade_dict = {}

        for index, row in df.iterrows():
            if row['IsTradeID'] == 'Y':
                trade_dict[row['TradeID']] = row['Value']
        logging.info("Mapped generated ID with trades")
        return trade_dict

    def add_generated_trade_id(self, df, trade_dict):
        if 'GeneratedTradeID' not in df.columns:
            df['GeneratedTradeID'] = None

        for index, row in df.iterrows():
            trade_id = row['TradeID']
            if trade_id in trade_dict:
                df.at[index, 'GeneratedTradeID'] = trade_dict[trade_id]
        logging.info("Added generated trade ID to DataFrame")
        return df

    import pandas as pd

    def generate_stubbing_result(self):
        rules_df = self.get_rules_dfs()
        stubbed_trades_with_identifiers_df = self.generate_stub_trades_with_identifiers_df()
        trade_id_rules_dict = self.create_trade_id_rule_mappings(stubbed_trades_with_identifiers_df)
        rules_resolver = RulesResolver(trade_id_rules_dict, rules_df)
        trade_id_rules_dict = rules_resolver.resolve_rules()
        resolved_trade_df = self.update_trade_df_with_rules_dict(stubbed_trades_with_identifiers_df,
                                                                            trade_id_rules_dict)
        generated_trade_dict = self.map_generated_id_with_trades(resolved_trade_df)
        result_df = self.add_generated_trade_id(resolved_trade_df, generated_trade_dict)
        self.stubbing_file_handler.add_stubbing_result_sheet(result_df, 'Stubbing_Result')
        logging.info(f"Stubbing result generated successfully.")


import pandas as pd
import random
import string

class RulesResolver:
    def __init__(self, trade_dict, rules_df):
        self.trade_dict = trade_dict
        self.rules_df = rules_df
        logging.info("Initialized RulesResolver")

    def numeric_rule_resolver(self, length):
        return ''.join(random.choices(string.digits, k=length))

    def string_rule_resolver(self, length, pattern):
        chars = string.ascii_letters
        if pattern and 'upper' in pattern.lower():
            chars = chars.upper()
        elif pattern and 'lower' in pattern.lower():
            chars = chars.lower()
        return ''.join(random.choices(chars, k=int(length)))

    def alphanumeric_rule_resolver(self, length, pattern):
        alphanumeric_chars = string.ascii_letters + string.digits
        if pattern and 'upper' in pattern.lower():
            return ''.join(random.choices(alphanumeric_chars.upper(), k=int(length)))
        elif pattern and 'lower' in pattern.lower():
            return ''.join(random.choices(alphanumeric_chars.lower(), k=int(length)))
        else:
            return ''.join(random.choices(alphanumeric_chars, k=int(length)))

    def date_rule_resolver(self, length, pattern, unit):
        if not pattern:
            pattern = '%d-%m-%Y'

        current_date = datetime.now()

        try:
            formatted_date = current_date.strftime(pattern)
        except ValueError:
            raise Exception("Invalid date pattern")

        if not length:
            return formatted_date

        try:
            offset = int(length)
        except ValueError:
            raise Exception("Invalid length value")

        if unit == 'days':
            new_date = current_date + timedelta(days=offset)
        elif unit == 'months':
            new_date = current_date + timedelta(days=offset * 30)
        elif unit == 'years':
            new_date = current_date + timedelta(days=offset * 365)
        else:
            raise Exception("Invalid unit value")

        return new_date.strftime(pattern)

    def resolve_rule(self, rule_id):
        if rule_id not in self.rules_df['RuleID'].values:
            raise Exception("RuleID not present")

        rule_row = self.rules_df[self.rules_df['RuleID'] == rule_id].iloc[0]

        rule_type = rule_row['Type']
        length = int(rule_row['Length']) if rule_row['Length'] else 0
        pattern = rule_row['Pattern']
        unit = rule_row['Unit'].lower() if rule_row['Unit'] else 'days'

        rule_resolvers = {
            'Numeric': self.numeric_rule_resolver(length),
            'String': self.string_rule_resolver(length, pattern),
            'AlphaNumeric': self.alphanumeric_rule_resolver(length, pattern),
            'Date': self.date_rule_resolver(length, pattern, unit)
            # Add more conditions for other rule types here
        }

        if rule_type not in rule_resolvers:
            raise Exception("Unsupported rule type")

        generated_output = rule_resolvers[rule_type]
        logging.info(f"Resolved rule for RuleID {rule_id}: {generated_output}")
        return generated_output

    def resolve_rules(self):
        for trade_id, inner_dict in self.trade_dict.items():
            for rule_id, rule_str in inner_dict.items():
                resolved_value = self.resolve_rule(rule_id)
                inner_dict[rule_id] = resolved_value
        logging.info("Resolved rules for all trades")
        return self.trade_dict


# test.py
# from excel_processor import ExcelProcessor
# import pandas as pd

if __name__ == "__main__":
    stubbing_file_path = "input.xlsx"
    trade_processor = TradeDataProcessor(stubbing_file_path)
    trade_processor.generate_stubbing_result()
